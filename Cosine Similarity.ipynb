{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a271f569-57d3-487f-bf65-e03aa1732001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazon Trend Prediction based on TikTok Hashtags\n",
    "\n",
    "This repository contains code for the analysis of TikTok hashtag descriptions to predict trending products on Amazon. It includes a Python script that processes datasets and calculates cosine similarity between TikTok descriptions and Amazon search terms.\n",
    "\n",
    "## Python Script\n",
    "\n",
    "Below is the Python code used in this project. Each code block corresponds to a portion of the script with a specific function.\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "Before running the script, ensure you have Dask, Pandas, and Scikit-learn installed in your Python environment.\n",
    "\n",
    "```python\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e33bd81-c0b3-4b2c-bb96-054f1a8e37dd",
   "metadata": {},
   "source": [
    "## Data Loading:\n",
    "The datasets are loaded from Parquet files using Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6367d780-6785-4985-ba02-5c02c0541c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df = dd.read_parquet('nswAmz.parquet')\n",
    "tiktok_df = dd.read_parquet('nswTik.parquet')\n",
    "\n",
    "amazon_titles = amazon_df['Search_Term']\n",
    "tiktok_text = tiktok_df['description']\n",
    "\n",
    "amazon_titles = [str(item) for item in amazon_titles]\n",
    "tiktok_text = [str(item) for item in tiktok_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dccb0ec-de4f-4631-8d32-6deec81e0652",
   "metadata": {},
   "source": [
    "## Cosine Similarity Calculation:\n",
    "Define a function to calculate cosine similarity between two lists of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f96f436-ff48-4c8d-99bf-09864edcd52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(list1, list2):\n",
    "    # Create a single list for TF-IDF\n",
    "    combined_list = list1 + list2\n",
    "\n",
    "    # Initialize the vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Vectorize the text using TF-IDF\n",
    "    tfidf_matrix = vectorizer.fit_transform(combined_list)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    cos_sim_matrix = cosine_similarity(tfidf_matrix[:len(list1)], tfidf_matrix[len(list1):])\n",
    "\n",
    "    return cos_sim_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b970bcdf-60aa-44f3-a4a1-75613df458e9",
   "metadata": {},
   "source": [
    "## Saving Results to CSV:\n",
    "Define a function to save the similarity matrix to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fc0085-b33d-4913-975d-b5de6b4bf54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(similarity_matrix, list1, list2, dates_collected, reporting_dates, output_file):\n",
    "    # Prepare data for DataFrame\n",
    "    data = []\n",
    "    for i in range(len(list1)):\n",
    "        top_indices = similarity_matrix[i].argsort()[-1:][::-1]\n",
    "        for index in top_indices:\n",
    "            data.append([\n",
    "                list1[i],\n",
    "                dates_collected[i],\n",
    "                list2[index],\n",
    "                reporting_dates[index],\n",
    "                similarity_matrix[i][index]\n",
    "            ])\n",
    "    df = pd.DataFrame(data, columns=[\n",
    "        'Hashtag Description',\n",
    "        'Date Collected',\n",
    "        'SearchTerm',\n",
    "        'Reporting Date',\n",
    "        'Cosine Similarity'\n",
    "    ])\n",
    "    df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fdac2f-1947-407e-be19-250811f65c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 'date_collected' from tiktok_df DataFrame\n",
    "dates_collected = list(tiktok_df['date_collected'])\n",
    "\n",
    "# Extract 'Reporting Date' from amazon_df DataFrame\n",
    "reporting_dates = list(amazon_df['Reporting Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f1b719-2331-46bf-b135-e5b23177cdf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e55f9fa-6c79-407c-a351-a5498544fb90",
   "metadata": {},
   "source": [
    "## Processing in Chunks\r\n",
    "Due to memory limits, the script processes data in chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e5ddb6-6ecb-44cd-952b-eb0e4171a8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the memory limit, we need to write a for loop to run 12000 lines each time and totally run 20 times\n",
    "chunk_size = 12000\n",
    "\n",
    "for i in range(20):\n",
    "    start_index = i * chunk_size\n",
    "    end_index = start_index + chunk_size\n",
    "    if end_index > len(list1):\n",
    "        end_index = len(list1)\n",
    "    current_list1_chunk = list1[start_index:end_index]\n",
    "    similarity_matrix = calculate_cosine_similarity(current_list1_chunk, list2)\n",
    "    output_csv = f'cosine_similarity_output_part_{i+1}.csv'\n",
    "    save_to_csv(similarity_matrix, current_list1_chunk, list2, dates_collected, reporting_dates, output_csv)\n",
    "    print(f\"Results saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff76eb7-01bf-4340-9b6e-6b54c9e6f57a",
   "metadata": {},
   "source": [
    "## Merging CSV Files\r\n",
    "After processing, merge all CSV parts into a single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05502f7-cd0c-4865-9014-8938598d6ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "\n",
    "for i in range(1, 20):\n",
    "    df = pd.read_csv(f'cosine_similarity_output_part_{i}.csv', encoding='UTF-8')\n",
    "    dataframes.append(df)\n",
    "\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "combined_df.to_csv('combined_output.csv', index=False)\n",
    "print(\"All files have been merged into combined_output.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd6890f-a844-4f51-8acb-dcacbd7ce30e",
   "metadata": {},
   "source": [
    "## Sample Output\n",
    "Below is a sample output from the script, showcasing the data structure of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9d09d9-1f98-4387-b532-f4dc605c9a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hashtag Description Date Collected                 SearchTerm  Cosine Similarity  Cosine Similarity.1\n",
    "0                   _     04/07/2023             zzzquil liquid          04/15/2023             0.000000\n",
    "1                 ___     04/07/2023             zzzquil liquid          04/15/2023             0.000000\n",
    "2              _marwe     04/12/2023             zzzquil liquid          04/15/2023             0.000000\n",
    "3           musically     04/07/2023             zzzquil liquid          04/15/2023             0.000000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
